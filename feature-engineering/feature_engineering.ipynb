{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "** Feature engineering** is indeed a crucial step in the machine learning workflow, as it can have a significant impact on the performance of predictive models. \n",
        "\n",
        "Before diving into specific techniques, it's important to note that the goal of feature engineering is to create features that are informative, relevant, and *non*-redundant. Informative features provide useful information to the model, relevant features are related to the target variable, and non-redundant features don't overlap in terms of the information they provide.\n",
        "\n",
        "Now let's explore some common feature engineering techniques:\n",
        "\n",
        "1. **Scaling and normalization**: This technique is used to standardize the range of features. It's important because many machine learning algorithms are sensitive to the scale of features. Common scaling and normalization techniques include min-max scaling, z-score normalization, and log transformation.\n",
        "\n",
        "2. **One-hot encoding**: One-hot encoding is used to convert categorical features into binary features that can be used by machine learning algorithms. In this technique, each category is represented by a binary feature, with a value of 1 indicating the presence of the category and 0 indicating its absence.\n",
        "\n",
        "3. **Feature selection**: This technique involves selecting a subset of the most important features for the model. It's important because it can reduce the dimensionality of the feature space, which can lead to faster and more accurate models. Common feature selection techniques include correlation-based feature selection, recursive feature elimination, and principal component analysis.\n",
        "\n",
        "4. **Feature extraction**: Feature extraction involves creating new features from existing ones. This technique is useful when the existing features are not informative enough or when there are too many features. Common feature extraction techniques include principal component analysis, linear discriminant analysis, and non-negative matrix factorization.\n",
        "\n",
        "5. **Text preprocessing**: When working with text data, it's important to preprocess the data to extract relevant information. This may involve techniques such as tokenization, stemming, lemmatization, and stop-word removal.\n",
        "\n",
        "6. **Time-series feature engineering**: When working with time-series data, it's important to create features that capture the temporal patterns in the data. This may involve creating lagged features, rolling statistics, and trend indicators.\n",
        "\n",
        "7. **Image feature engineering**: When working with image data, it's important to create features that capture the visual patterns in the data. This may involve techniques such as edge detection, texture analysis, and feature extraction using deep learning models.\n",
        "\n",
        "These are just a few examples of the many feature engineering techniques available. It's important to choose the appropriate techniques based on the characteristics of the data and the specific requirements of the predictive model."
      ],
      "metadata": {
        "id": "flo9Fmc3aDL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "d={\n",
        "    'A': [1,2,None,4 ],\n",
        "   'B':[5,6,7,None],\n",
        "   'C':[None,8,9,10]\n",
        "\n",
        "}\n",
        "\n",
        "df=pd.DataFrame(d)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsOEaEoDaZtU",
        "outputId": "06499457-30f5-4692-fb68-b4444ee10ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A    B     C\n",
            "0  1.0  5.0   NaN\n",
            "1  2.0  6.0   8.0\n",
            "2  NaN  7.0   9.0\n",
            "3  4.0  NaN  10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_saK1utSZQ4g",
        "outputId": "6b2423a8-35ed-4cbb-bd2e-53982f2f88fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A    B    C\n",
            "1  2.0  6.0  8.0\n"
          ]
        }
      ],
      "source": [
        "#drop rows with missing values\n",
        "df_without_missing=df.dropna()\n",
        "print(df_without_missing)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputation missing  values can be replaced with estimated values\n",
        "#mean meadian mode impilation\n",
        "\n",
        "df_imputed=df.fillna(df.mean())\n",
        "print(df_imputed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfbNsMapdF5s",
        "outputId": "c0d64215-f4a3-4d5d-ea0e-28a7f3d68042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          A    B     C\n",
            "0  1.000000  5.0   9.0\n",
            "1  2.000000  6.0   8.0\n",
            "2  2.333333  7.0   9.0\n",
            "3  4.000000  6.0  10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop columns with missing value\n",
        "df_C_without_missing=df.dropna(axis=1)\n",
        "print(df_C_without_missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PMAzJrUcqvG",
        "outputId": "74a0ac7f-bd9a-47b5-94aa-f117c02a081e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: [0, 1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "data = {'Color': ['Red', 'Blue', None, 'Red', 'Blue','Green','Red'],\n",
        " 'Size': ['Small', 'Medium', 'Large', None, 'Small','Large','Small']}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcaPv3mSeQD5",
        "outputId": "e0f08ac6-8738-48e7-fe5e-6dbee75659ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color    Size\n",
            "0    Red   Small\n",
            "1   Blue  Medium\n",
            "2   None   Large\n",
            "3    Red    None\n",
            "4   Blue   Small\n",
            "5  Green   Large\n",
            "6    Red   Small\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indicator_variables=pd.get_dummies(df)\n",
        "print(indicator_variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBYimlIafJtT",
        "outputId": "24a43f0a-9ef9-4838-c01a-e00d59b52515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color_Blue  Color_Green  Color_Red  Size_Large  Size_Medium  Size_Small\n",
            "0           0            0          1           0            0           1\n",
            "1           1            0          0           0            1           0\n",
            "2           0            0          0           1            0           0\n",
            "3           0            0          1           0            0           0\n",
            "4           1            0          0           0            0           1\n",
            "5           0            1          0           1            0           0\n",
            "6           0            0          1           0            0           1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "data = {'Color': ['Red', 'Blue', None, 'Red', 'Blue','green'],\n",
        " 'Size': ['Small', 'Medium', 'Large', None, 'Small','Large']}\n",
        "df = pd.DataFrame(data)\n",
        "indicator_variables=pd.get_dummies(df)\n",
        "impute = SimpleImputer(strategy=\"most_frequent\")\n",
        "imputed_values=impute.fit_transform(indicator_variables)\n",
        "print(imputed_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU2GKJeTfjuv",
        "outputId": "d73a25e1-74c7-4e13-dbd6-1fbf4e652b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 0 0 1]\n",
            " [1 0 0 0 1 0]\n",
            " [0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [1 0 0 0 0 1]\n",
            " [0 0 1 1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "data = {'Color': ['Red', 'Blue', None, 'Red', 'Blue','green'],\n",
        " 'Size': ['Small', 'Medium', 'Large', None, 'Small','Large']}\n",
        "df = pd.DataFrame(data)\n",
        "indicator_variables=pd.get_dummies(df)\n",
        "impute = SimpleImputer(strategy=\"most_frequent\")\n",
        "imputed_values=impute.fit_transform(indicator_variables)\n",
        "imputed_df=pd.DataFrame(imputed_values, columns=indicator_variables.columns)\n",
        "print(imputed_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPzF-dYWgqxq",
        "outputId": "c091f7a2-35d1-4c32-d2b1-08e0e2831e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color_Blue  Color_Red  Color_green  Size_Large  Size_Medium  Size_Small\n",
            "0           0          1            0           0            0           1\n",
            "1           1          0            0           0            1           0\n",
            "2           0          0            0           1            0           0\n",
            "3           0          1            0           0            0           0\n",
            "4           1          0            0           0            0           1\n",
            "5           0          0            1           1            0           0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2 Dealing with Categorical Variables**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ci77h3Ku4JyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**one hot encoding**\n",
        "In this approach, each category of a categorical variable is transformed into a binary feature. For example, if a variable \"color\" has categories \"red,\" \"blue,\" and\n",
        "\"green,\" it would be encoded as three separate binary features: \"color_red,\" \"color_blue,\" and \"color_green.\"\n"
      ],
      "metadata": {
        "id": "4lO6z2am6MQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data={'color':['red','blue','green','red','blue'],\n",
        "      'size':['S','M','L','S','L']}\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "\n",
        "one_hot_encoded=pd.get_dummies(df)\n",
        "print(one_hot_encoded)"
      ],
      "metadata": {
        "id": "hObqVb5CHQhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24afd773-97be-4328-87f1-8cef150c924c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   color_blue  color_green  color_red  size_L  size_M  size_S\n",
            "0           0            0          1       0       0       1\n",
            "1           1            0          0       0       1       0\n",
            "2           0            1          0       1       0       0\n",
            "3           0            0          1       0       0       1\n",
            "4           1            0          0       1       0       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Label encoding** assigns a unique numerical label to each category of a categorical variable. However, this method introduces an implicit ordering among\n",
        "categories, which may mislead the model. It is typically suitable for ordinal variables where the order matters.\n"
      ],
      "metadata": {
        "id": "tbBkJg8S7TVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "colors=['Red','Blue','Green','Red','Green']\n",
        "label_encorder=LabelEncoder()\n",
        "encordered_colors=label_encorder.fit_transform(colors)\n",
        "print(encordered_colors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoMvu_D27V7D",
        "outputId": "5f879817-326a-4601-9f6f-14e9b8f9c994"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 0 1 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Target Encoding:**\n",
        "Target encoding replaces each category with the mean target value of the corresponding category. This technique can be useful when there is a correlation\n",
        "between the categorical variable and the target variable.\n",
        "\n",
        "In below code, the KFold class from sklearn.model_selection is imported . It creates a kf object that will perform k-fold cross-validation. The n_splits parameter is set to 3, meaning the data will be split into 3 folds. The shuffle parameter is set to True to randomize the sample indices before splitting.\n",
        "\n",
        "The code then uses a for loop to iterate over the train and test indices generated by kf.split(data). You can use these indices to select the corresponding rows from your data DataFrame and perform your model training and evaluation within the loop."
      ],
      "metadata": {
        "id": "Gh97SSgi8Z3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "data=pd.DataFrame({\n",
        "     'category': ['A', 'B', 'A', 'C', 'B', 'C'],\n",
        "     'target': [1, 0, 1, 0, 1, 0]\n",
        "\n",
        "})\n",
        "\n",
        "data['category_target_encoded'] = 0\n",
        "# Perform target encoding using K-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for train_index, val_index in kf.split(data):\n",
        " train_data = data.iloc[train_index]\n",
        " val_data = data.iloc[val_index]\n",
        " \n",
        " # Calculate the mean target value for each category in the training set\n",
        " category_mean = train_data.groupby('category')['target'].mean()\n",
        " \n",
        " # Map the mean target values to the corresponding categories in the validation set\n",
        " val_data['category_target_encoded'] = val_data['category'].map(category_mean)\n",
        " \n",
        " # Update the target-encoded values in the main dataset\n",
        " data.iloc[val_index] = val_data\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSMoNZwL9_v_",
        "outputId": "33ed210a-f9d5-4848-da7d-af7d27cd0488"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  category  target  category_target_encoded\n",
            "0        A       1                        1\n",
            "1        B       0                        1\n",
            "2        A       1                        1\n",
            "3        C       0                        0\n",
            "4        B       1                        0\n",
            "5        C       0                        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-b52cf6197a78>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_data['category_target_encoded'] = val_data['category'].map(category_mean)\n",
            "<ipython-input-9-b52cf6197a78>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_data['category_target_encoded'] = val_data['category'].map(category_mean)\n",
            "<ipython-input-9-b52cf6197a78>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_data['category_target_encoded'] = val_data['category'].map(category_mean)\n",
            "<ipython-input-9-b52cf6197a78>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_data['category_target_encoded'] = val_data['category'].map(category_mean)\n",
            "<ipython-input-9-b52cf6197a78>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_data['category_target_encoded'] = val_data['category'].map(category_mean)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frequency Encoding:**\n",
        "Frequency encoding replaces each category with its frequency in the dataset. It can capture the information about the distribution of categories, especially\n",
        "when certain categories occur more frequently than others"
      ],
      "metadata": {
        "id": "TtT0Kz5sCNMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Sample dataset with a categorical feature 'category'\n",
        "data = pd.DataFrame({\n",
        " 'category': ['A', 'B', 'A', 'C', 'B', 'C']\n",
        "})\n",
        "# Calculate the frequency of each category in the dataset\n",
        "category_counts = data['category'].value_counts()\n",
        "# Create a new column to store the frequency-encoded values\n",
        "data['category_frequency_encoded'] = data['category'].map(category_counts) / len(data)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4oxnsNCCSbF",
        "outputId": "bc5a4a84-7dbe-497a-da51-b7b2f8119ade"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  category  category_frequency_encoded\n",
            "0        A                    0.333333\n",
            "1        B                    0.333333\n",
            "2        A                    0.333333\n",
            "3        C                    0.333333\n",
            "4        B                    0.333333\n",
            "5        C                    0.333333\n"
          ]
        }
      ]
    }
  ]
}